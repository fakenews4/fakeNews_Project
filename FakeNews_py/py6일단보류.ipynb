{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. `csv` 파일 자동 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일 로드\n",
    "data = pd.read_csv(\"C:/py/fakeNEWs_project/News_dataset3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test 분할 (80:20)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분할된 데이터 저장\n",
    "train_data.to_csv(\"train.csv\", index=False, encoding=\"utf-8\")\n",
    "test_data.to_csv(\"test.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "file_path = \"C:/py/fakeNEWs_project/News_dataset3.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 데이터 분리 (80:20)\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train = vectorizer.fit_transform(train_data['Content'])\n",
    "X_test = vectorizer.transform(test_data['Content'])\n",
    "\n",
    "# 레이블 추출\n",
    "y_train = train_data['Label']\n",
    "y_test = test_data['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9991079393398751\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1110\n",
      "           1       1.00      1.00      1.00      1132\n",
      "\n",
      "    accuracy                           1.00      2242\n",
      "   macro avg       1.00      1.00      1.00      2242\n",
      "weighted avg       1.00      1.00      1.00      2242\n",
      "\n",
      "Model and vectorizer saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터 평가\n",
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, predictions))\n",
    "\n",
    "# 모델 및 벡터라이저 저장\n",
    "joblib.dump(model, \"logistic_model.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "print(\"Model and vectorizer saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# 파일 경로 설정\n",
    "model_path = 'logistic_model.pkl'  # 학습된 모델 파일\n",
    "vectorizer_path = 'tfidf_vectorizer.pkl'  # 학습된 벡터라이저 파일\n",
    "sample_file_path = 'C:/py/fakeNEWs_project/Sample_News_Dataset.csv'  # 실험용 데이터 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 샘플 데이터 로드\n",
    "sample_data = pd.read_csv(sample_file_path, encoding='euc-kr')\n",
    "\n",
    "# 2. 학습된 모델과 벡터라이저 로드\n",
    "try:\n",
    "    model = joblib.load(model_path)\n",
    "    vectorizer = joblib.load(vectorizer_path)\n",
    "except FileNotFoundError as e:\n",
    "    raise Exception(\"모델 또는 벡터라이저 파일이 누락되었습니다. 올바른 파일을 제공해주세요.\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 샘플 데이터 벡터화\n",
    "sample_X = vectorizer.transform(sample_data['Content'])\n",
    "\n",
    "# 4. 예측 수행\n",
    "predictions = model.predict(sample_X)\n",
    "\n",
    "# 5. 결과 추가\n",
    "sample_data['Prediction'] = predictions\n",
    "sample_data['Prediction'] = sample_data['Prediction'].map({0: \"Fake\", 1: \"Real\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Title Prediction\n",
      "0  알코올이 코로나에 좋다…가짜뉴스에 최소 800명 사망       Fake\n",
      "1     알코올이 코로나에 좋다'는 가짜뉴스로 인한 피해       Fake\n"
     ]
    }
   ],
   "source": [
    "# 6. 결과 출력\n",
    "print(sample_data[['Title', 'Prediction']])\n",
    "\n",
    "# 결과를 CSV로 저장하려면\n",
    "# sample_data.to_csv(\"predictions.csv\", index=False, encoding=\"euc-kr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
