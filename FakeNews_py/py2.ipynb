{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install transformers pandas torch gradio requests beautifulsoup4\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, pipeline\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 기사 크롤링 함수\n",
    "def extract_article_content(url):\n",
    "    \"\"\"\n",
    "    주어진 URL에서 기사 본문을 추출.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # 뉴스 사이트별 본문 CSS 셀렉터\n",
    "        selectors = [\n",
    "            \"div#dic_area\",  # 네이버 뉴스\n",
    "            \"div.article_body\",  # 예: 특정 뉴스 사이트\n",
    "            \"div#articleBodyContents\",  # 예: 다음 뉴스\n",
    "            \"article\",  # 일반적인 <article> 태그\n",
    "            \"div.content\",  # 기타 사이트\n",
    "        ]\n",
    "\n",
    "        # 본문 추출\n",
    "        for selector in selectors:\n",
    "            content = soup.select_one(selector)\n",
    "            if content and content.get_text(strip=True):\n",
    "                return content.get_text(separator=\" \", strip=True)\n",
    "        \n",
    "        # 본문을 찾지 못한 경우\n",
    "        return \"기사를 읽을 수 없습니다. 링크를 확인하세요.\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"오류 발생: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 초기화 함수\n",
    "def initialize_models():\n",
    "    \"\"\"\n",
    "    RoBERTa 분류기와 T5 요약 모델 초기화.\n",
    "    \"\"\"\n",
    "    # 로버타 모델 초기화\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "    classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    # 요약 모델 초기화\n",
    "    summarizer = pipeline(\"summarization\", model=\"t5-small\", tokenizer=\"t5-small\")\n",
    "    \n",
    "    return classifier, summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 기사 분석 함수\n",
    "def analyze_article(url):\n",
    "    \"\"\"\n",
    "    URL에서 기사를 크롤링하고 요약 및 분류.\n",
    "    \"\"\"\n",
    "    # 기사 본문 추출\n",
    "    article_content = extract_article_content(url)\n",
    "    if \"오류 발생\" in article_content or \"기사를 읽을 수 없습니다\" in article_content:\n",
    "        return article_content, \"분류 불가\", \"요약 불가\"\n",
    "    \n",
    "    # 모델 초기화\n",
    "    classifier, summarizer = initialize_models()\n",
    "\n",
    "    # 가짜 뉴스 판별\n",
    "    try:\n",
    "        classification_result = classifier(article_content[:512])[0][\"label\"]  # 'LABEL_0' 또는 'LABEL_1'\n",
    "        classification = \"진짜 뉴스\" if classification_result == \"LABEL_0\" else \"가짜 뉴스\"\n",
    "    except Exception as e:\n",
    "        classification = f\"분류 실패: {e}\"\n",
    "\n",
    "    # 기사 요약\n",
    "    try:\n",
    "        summary_result = summarizer(article_content[:512], max_length=50, min_length=10, do_sample=False)\n",
    "        summary = summary_result[0][\"summary_text\"]\n",
    "    except Exception as e:\n",
    "        summary = f\"요약 실패: {e}\"\n",
    "\n",
    "    return article_content, classification, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Gradio 인터페이스 정의\n",
    "def gradio_interface(url):\n",
    "    article_content, classification, summary = analyze_article(url)\n",
    "    return article_content, classification, summary\n",
    "\n",
    "# Gradio 설정\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_interface,\n",
    "    inputs=gr.Textbox(label=\"기사 링크\", placeholder=\"뉴스 링크를 입력하세요\"),\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"기사 본문\"),\n",
    "        gr.Textbox(label=\"가짜 뉴스 여부\"),\n",
    "        gr.Textbox(label=\"요약된 내용\")\n",
    "    ],\n",
    "    title=\"가짜 뉴스 탐지 및 요약기\",\n",
    "    description=\"기사 링크를 입력하면 본문을 크롤링하고, 요약 및 가짜 뉴스 여부를 판단합니다.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://dcd8d2822c0cc29cae.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://dcd8d2822c0cc29cae.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1026 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
