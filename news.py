from fastapi import FastAPI, HTTPException, File, UploadFile
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import shutil
import requests
from bs4 import BeautifulSoup
from fastapi.middleware.cors import CORSMiddleware
import os
import traceback
import asyncio
import ollama
from collections import Counter
from konlpy.tag import Okt
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time

app = FastAPI()

# í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ê¸° (Okt)
okt = Okt()

# Pydantic ëª¨ë¸ë“¤
class UrlRequest(BaseModel):
    url: str

class QuestionRequest(BaseModel):
    question: str

class SummarizeRequest(BaseModel):
    content: str

class TextRequest(BaseModel):
    content: str

class keywordRequest(BaseModel):
    content: str

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/")
async def root():
    return {"message": "FastAPI ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤!"}

@app.post("/keywords")
async def extract_keywords_from_content(request: UrlRequest):
    try:
        url = request.url
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            raise HTTPException(status_code=500, detail="ì›¹ í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨")
        
        soup = BeautifulSoup(response.content, 'html.parser')

        # ì´ë¯¸ì§€, figcaption, title ì†ì„±ì´ ìˆëŠ” span íƒœê·¸ ì œê±°
        for img in soup.find_all('img'):
            img.decompose()
        for figcaption in soup.find_all('figcaption'):
            figcaption.decompose()
        for span in soup.find_all('span', title=True):
            span.decompose()

        # ë‹¤ì–‘í•œ íƒœê·¸ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        article_content = ""
        for tag in ["article"]:
            for element in soup.find_all(tag):
                article_content += element.get_text(separator=" ") + " "

        if not article_content.strip():
            raise HTTPException(status_code=500, detail="í¬ë¡¤ë§ëœ ì½˜í…ì¸ ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # í‚¤ì›Œë“œ ì¶”ì¶œ (ìƒìœ„ 1ê°œ)
        keywords = extract_keywords(article_content, top_n=1)
        print("âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ:", keywords)

        return {"keywords": keywords}

    except requests.exceptions.RequestException as e:
        raise HTTPException(status_code=500, detail=f"ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    except Exception as e:
        print(f"ğŸ”¥ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/ask")
async def ask_question(request: QuestionRequest):
    try:
        print(f"ğŸ“© ì‚¬ìš©ì ì§ˆë¬¸: {request.question}")
        response = await asyncio.to_thread(
            ollama.chat,
            model='gemma2',
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ í•œêµ­ì–´ ì±—ë´‡ì…ë‹ˆë‹¤."},
                {"role": "user", "content": request.question}
            ]
        )
        if "message" not in response:
            print(f"âš ï¸ Ollama ì‘ë‹µ ì˜¤ë¥˜: {response}")
            raise HTTPException(status_code=500, detail=f"Ollama ì‘ë‹µ ì˜¤ë¥˜: {response}")

        chatbot_reply = response["message"]
        print(f"ğŸ¤– ì±—ë´‡ ì‘ë‹µ: {chatbot_reply}")
        return {"reply": chatbot_reply}

    except Exception as e:
        error_details = traceback.format_exc()
        print(f"ğŸ”¥ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ:\n{error_details}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/crawl")
async def crawl_url(request: UrlRequest):
    url = request.url
    try:
        options = Options()
        options.headless = True
        options.add_argument("--ignore-certificate-errors")
        
        driver = webdriver.Chrome(options=options)
        driver.get(url)
        time.sleep(3)

        try:
            content = driver.find_element(By.TAG_NAME, 'article').text
        except Exception as e:
            content = ""
            print(f"ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨: {e}")

        driver.quit()

        if content:
            return {"extracted_content": content}
        else:
            raise HTTPException(status_code=500, detail="ì›¹ í˜ì´ì§€ì—ì„œ ì½˜í…ì¸ ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

@app.post("/summarize")
async def summarize_content(request: SummarizeRequest):
    try:
        print(f"ğŸ“© ìš”ì•½ ìš”ì²­ëœ ì½˜í…ì¸ : {request.content}")
        summarize_question = f"ë‹¤ìŒ ë‚´ìš©ì„ ìš”ì•½í•´ ì£¼ì„¸ìš”: {request.content}"
        response = await asyncio.to_thread(
            ollama.chat,
            model='gemma2',
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ í•œêµ­ì–´ ì±—ë´‡ì…ë‹ˆë‹¤."},
                {"role": "user", "content": summarize_question}
            ]
        )
        if "message" not in response:
            raise HTTPException(status_code=500, detail="Ollama ì‘ë‹µ ì˜¤ë¥˜")
        summary = response["message"]
        print(f"ğŸ¤– ìš”ì•½ëœ ë‚´ìš©: {summary}")
        return {"summary": summary}
    except Exception as e:
        print(f"ğŸ”¥ ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

class TextRequest(BaseModel):
    content: str

def extract_keywords(text, top_n=1):
    """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
    words = okt.pos(text)
    print("ğŸ“Œ í˜•íƒœì†Œ ë¶„ì„ ê²°ê³¼:", words)  # ğŸ”¥ ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€

    # ê³ ìœ ëª…ì‚¬(Nnp)ì™€ ì¼ë°˜ëª…ì‚¬(Noun) ì¶”ì¶œ
    proper_nouns = [word for word, pos in words if pos == 'Nnp']
    common_nouns = [word for word, pos in words if pos == 'Noun']
    print("âœ… ê³ ìœ ëª…ì‚¬:", proper_nouns)  # ğŸ”¥ ë¡œê·¸ ì¶”ê°€
    print("âœ… ì¼ë°˜ëª…ì‚¬:", common_nouns)

    # ê³ ìœ ëª…ì‚¬ì™€ ì¼ë°˜ëª…ì‚¬ í•©ì¹˜ê¸°
    all_nouns = proper_nouns + common_nouns
    all_nouns = [word for word in all_nouns if len(word) > 1]  # ê¸¸ì´ê°€ 1ë³´ë‹¤ í° ë‹¨ì–´ë§Œ í•„í„°ë§

    # ëª…ì‚¬ ì¹´ìš´íŒ…
    word_counts = Counter(all_nouns)
    filtered_words = [word for word, _ in word_counts.most_common(top_n) if len(word) > 1]
    
    # ë””ë²„ê¹… ì¶œë ¥
    print("âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ:", filtered_words)
    
    return filtered_words if filtered_words else ["í‚¤ì›Œë“œ ì—†ìŒ"]


@app.post("/upload")
async def upload_file(news_file: UploadFile = File(...)):  # âœ… news_fileì˜ ì´ë¦„ì´ ë§ëŠ”ì§€ í™•ì¸!
    if not news_file.filename.endswith(".txt"):
        raise HTTPException(status_code=400, detail="ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .txt íŒŒì¼ë§Œ ì—…ë¡œë“œí•˜ì„¸ìš”.")

    content = await news_file.read()  # ğŸ”¥ íŒŒì¼ ì½ê¸°
    text_content = content.decode("utf-8").strip()

    print("ğŸ“‚ [UPLOAD] íŒŒì¼ ë‚´ìš© (200ìê¹Œì§€):", text_content[:200])  # ğŸ”¥ ì²« 200ìë§Œ ì¶œë ¥

    if not text_content:
        raise HTTPException(status_code=400, detail="íŒŒì¼ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    return {"success": True, "content": text_content}

async def prevent_get_upload():
    raise HTTPException(status_code=405, detail="ì´ ê²½ë¡œëŠ” POST ìš”ì²­ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")

@app.post("/keywords_from_text")
async def extract_keywords_from_text(data: dict):
    content = data.get("content", "").strip()
    
    print("ğŸ” í‚¤ì›Œë“œ ì¶”ì¶œ ìš”ì²­ëœ í…ìŠ¤íŠ¸:", content[:200])  # ğŸ”¥ ì²« 200ê¸€ì ì¶œë ¥

    if not content:
        raise HTTPException(status_code=400, detail="ì¶”ì¶œí•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    keywords = extract_keywords(content, top_n=1)  # âœ… í‚¤ì›Œë“œ 1ê°œ ì¶”ì¶œ
    print("âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ:", keywords)

    return {"success": True, "keywords": keywords}

