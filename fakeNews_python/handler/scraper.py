import requests
from bs4 import BeautifulSoup
from transformers import pipeline

# âœ… í•œêµ­ì–´ ë‰´ìŠ¤ ìš”ì•½ ëª¨ë¸ (KoBART ê¸°ë°˜)
summarizer = pipeline(
    "summarization",
    model="ainize/kobart-news",
    tokenizer="ainize/kobart-news"
)

def scrape_naver_article(url: str):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ í›„ KoBART ëª¨ë¸ë¡œ ìš”ì•½
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
    }

    try:
        print(f"ğŸ› ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘: {url}")

        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")

        # âœ… ë³¸ë¬¸ í¬ë¡¤ë§ (ë„¤ì´ë²„ ë‰´ìŠ¤ êµ¬ì¡° ë°˜ì˜)
        article_body = soup.find("article", id="dic_area")
        if not article_body:
            return {"error": "âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        content_text = "\n".join(article_body.stripped_strings).strip()
        if not content_text:
            return {"error": "âŒ í¬ë¡¤ë§ëœ ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}

        # âœ… ì…ë ¥ ê¸¸ì´ ì œí•œ (1024ì ì´í•˜)
        trimmed_text = content_text[:1024]

        # âœ… ë³¸ë¬¸ì´ ì¶©ë¶„íˆ ê¸¸ ë•Œë§Œ ìš”ì•½ ì‹¤í–‰ (300ì ì´ìƒ)
        if len(trimmed_text) > 300:
            try:
                summary = summarizer(trimmed_text, max_length=300, min_length=150, do_sample=False)
                summarized_text = summary[0]['summary_text']
            except Exception as e:
                return {"error": f"âŒ ìš”ì•½ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
        else:
            summarized_text = trimmed_text  # 300ì ì´í•˜ë©´ ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©

        print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ë° ìš”ì•½ ì„±ê³µ\nìš”ì•½: {summarized_text[:100]}...")
        return {"content": summarized_text}

    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}
