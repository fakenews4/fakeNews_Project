import requests
from bs4 import BeautifulSoup
import google.generativeai as genai
import tensorflow as tf

# âœ… Google AI API ì„¤ì • (API Key í•„ìš”)
genai.configure(api_key="AIzaSyAqiutR9Uc1Q4DUtRQdiAu58U6apM8jmek")  # ë°œê¸‰ë°›ì€ API í‚¤ ì…ë ¥

def summarize_news(text):
    """Google Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜"""
    model = genai.GenerativeModel("gemini-pro")  # Gemini ëª¨ë¸ ì„ íƒ
    response = model.generate_content(f"ë‹¤ìŒ ë‰´ìŠ¤ë¥¼ 300ì ì´í•˜ë¡œ ìš”ì•½í•´ì¤˜:\n\n{text}")
    return response.text  # ìš”ì•½ëœ ë‰´ìŠ¤ ë°˜í™˜

def scrape_naver_article(url: str):
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ í¬ë¡¤ë§ ë° ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
    }

    try:
        print(f"ğŸ› ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘: {url}")

        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()

        soup = BeautifulSoup(response.text, "html.parser")

        # âœ… ë³¸ë¬¸ í¬ë¡¤ë§ (ë„¤ì´ë²„ ë‰´ìŠ¤ êµ¬ì¡° ë°˜ì˜)
        article_body = soup.find("article", id="dic_area")
        if not article_body:
            return {"error": "âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ ë³¸ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        content_text = "\n".join(article_body.stripped_strings).strip()
        if not content_text:
            return {"error": "âŒ í¬ë¡¤ë§ëœ ë³¸ë¬¸ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}

        print(f"âœ… ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì„±ê³µ\në³¸ë¬¸: {content_text[:100]}...")

        # âœ… ìš”ì•½ ê¸°ëŠ¥ ì¶”ê°€
        summary = summarize_news(content_text)
        print(f"âœ… ë‰´ìŠ¤ ìš”ì•½ ì™„ë£Œ: {summary[:100]}...")

        return {"content": content_text, "summary": summary}

    except Exception as e:
        print(f"âŒ ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return {"error": str(e)}