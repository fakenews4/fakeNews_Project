import requests
import urllib.parse
import pandas as pd
import os
from config.config import get_db_connection,PUBLISHER_MAPPING
from urllib.parse import urlparse

def get_publisher_from_url(originallink):
    """ ì›ë³¸ ë§í¬ì—ì„œ ë„ë©”ì¸ì„ ì¶”ì¶œí•˜ê³  ì–¸ë¡ ì‚¬ ì´ë¦„ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ """
    if not originallink:  # ğŸ”´ `originallink`ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ë°˜í™˜
        return "ì–¸ë¡ ì‚¬"

    parsed_url = urlparse(originallink)
    domain = parsed_url.netloc.replace("www.", "")  # `www.` ì œê±°

    return PUBLISHER_MAPPING.get(domain, "ì§€ë°©ì–¸ë¡ ì‚¬")  # ë§¤ì¹­ ì•ˆ ë˜ë©´ `Unknown` ë°˜í™˜

# API í˜¸ì¶œ: í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
def fetch_news_from_api(keywords, display=100):
    client_id = os.getenv("NAVER_KEY")
    client_secret = os.getenv("NAVER_SECRET_KEY")

    query = " OR ".join(keywords)
    encoded_query = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/news.json?query={encoded_query}&display={display}"

    headers = {
        "X-Naver-Client-Id": client_id,
        "X-Naver-Client-Secret": client_secret,
    }

    response = requests.get(url, headers=headers)
    
    if response.status_code == 200:
        news_items = response.json().get("items", [])

        for news in news_items:
            originallink = news.get("originallink", news.get("link", ""))
            news["publisher"] = get_publisher_from_url(originallink)  # âœ… ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€

        return news_items
    else:
        print(f"Error {response.status_code}: {response.text}")
        return []

# DBì— ì¤‘ë³µ í™•ì¸ ë° ë‰´ìŠ¤ ì €ì¥
def save_news_to_db(news_items):
    conn = get_db_connection()
    cursor = conn.cursor()

    for news in news_items:
        title = news["title"]
        publisher = news.get("publisher", "ì–¸ë¡ ì‚¬")  # âœ… ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ê°€

        # ì¤‘ë³µ ê²€ì‚¬: ê°™ì€ ì œëª©ì˜ ê¸°ì‚¬ê°€ DBì— ìˆëŠ”ì§€ í™•ì¸
        cursor.execute("SELECT COUNT(*) FROM news WHERE title = %s", (title,))
        if cursor.fetchone()[0] == 0:
            # ì¤‘ë³µë˜ì§€ ì•Šì€ ê²½ìš°ë§Œ ì €ì¥
            cursor.execute("""
            INSERT INTO news (title, link, description, publisher, category)
            VALUES (%s, %s, %s, %s, %s)
            """, (
                title,
                news["link"],
                news["description"],
                publisher,  # âœ… `publisher` ì €ì¥
                "general"
            ))

    conn.commit()
    conn.close()

# DBì—ì„œ 9ê°œì˜ ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
def get_news_recommendations():
    conn = get_db_connection()
    df = pd.read_sql_query("SELECT * FROM news LIMIT 9", conn)
    conn.close()
    return df

# DBì—ì„œ í‚¤ì›Œë“œì™€ ê´€ë ¨ëœ ê¸°ì‚¬ 9ê°œ ëœë¤ ì„ íƒ
def get_random_news_recommendations(keywords):
    conn = get_db_connection()
    
    # í‚¤ì›Œë“œë¥¼ í¬í•¨í•˜ëŠ” ê¸°ì‚¬ë¥¼ ê²€ìƒ‰
    keyword_conditions = " OR ".join([f"title LIKE '%%{keyword}%%'" for keyword in keywords])
    query = f"SELECT * FROM news WHERE {keyword_conditions}"
    df = pd.read_sql_query(query, conn)
    conn.close()

    # ê¸°ì‚¬ê°€ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜
    if df.empty:
        return pd.DataFrame()

    # ê¸°ì‚¬ê°€ 9ê°œ ì´ìƒì´ë©´ ëœë¤ìœ¼ë¡œ 9ê°œ ì„ íƒ
    return df.sample(n=min(9, len(df)))
