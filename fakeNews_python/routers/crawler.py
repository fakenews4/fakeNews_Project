from fastapi import APIRouter, HTTPException
from handler.scraper import scrape_naver_article
from handler.models import classify_news

router = APIRouter()

@router.get("/api/crawler")
async def fetch_and_analyze_news(url: str):
    """
    ë‰´ìŠ¤ URLì„ ë°›ì•„ì„œ í¬ë¡¤ë§ í›„ AI ëª¨ë¸ë¡œ ë¶„ì„í•˜ì—¬ ê°€ì§œ ë‰´ìŠ¤ ì—¬ë¶€ë¥¼ íŒë³„
    """
    try:
        # âœ… 1ï¸âƒ£ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰
        result = scrape_naver_article(url)
        if not result or "error" in result:
            raise HTTPException(status_code=404, detail="ê¸°ì‚¬ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        content = result.get("content", "")
        summary = result.get("summary", "ìš”ì•½ ì—†ìŒ")

        # âœ… í¬ë¡¤ë§ ê²°ê³¼ í™•ì¸ ì¶œë ¥
        print("\nğŸ“° [í¬ë¡¤ë§ ê²°ê³¼]")
        print(f"ğŸ”¹ ë³¸ë¬¸: {content[:500]}...")  # ê¸´ ë‚´ìš©ì´ë¯€ë¡œ ì•ë¶€ë¶„ë§Œ ì¶œë ¥
        print(f"ğŸ”¹ ìš”ì•½: {summary}")

        # âœ… 2ï¸âƒ£ AI ëª¨ë¸ íŒë³„ ì‹¤í–‰
        analysis_result = classify_news(content)
        print(analysis_result)

        # âœ… 3ï¸âƒ£ ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "content": content,
            "summary": summary,
            "analysis": analysis_result
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
